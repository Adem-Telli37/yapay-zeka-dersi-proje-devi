{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1ee31a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "import re\n",
    "import csv\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# NLTK verilerini indir (ilk çalıştırmada gerekli)\n",
    "nltk.download('punkt', quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8e2832a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wordcloud\n",
      "  Obtaining dependency information for wordcloud from https://files.pythonhosted.org/packages/00/09/abb305dce85911b8fba382926cfc57f2f257729e25937fdcc63f3a1a67f9/wordcloud-1.9.4-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading wordcloud-1.9.4-cp311-cp311-win_amd64.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\ademt\\anaconda3\\lib\\site-packages (from wordcloud) (1.24.3)\n",
      "Requirement already satisfied: pillow in c:\\users\\ademt\\anaconda3\\lib\\site-packages (from wordcloud) (10.0.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\ademt\\anaconda3\\lib\\site-packages (from wordcloud) (3.7.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ademt\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ademt\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ademt\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\ademt\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ademt\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (23.1)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\ademt\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ademt\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ademt\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n",
      "Downloading wordcloud-1.9.4-cp311-cp311-win_amd64.whl (299 kB)\n",
      "   ---------------------------------------- 0.0/299.9 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/299.9 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/299.9 kB ? eta -:--:--\n",
      "   ----- --------------------------------- 41.0/299.9 kB 326.8 kB/s eta 0:00:01\n",
      "   ----------- --------------------------- 92.2/299.9 kB 655.4 kB/s eta 0:00:01\n",
      "   ---------------------- --------------- 174.1/299.9 kB 952.6 kB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 256.0/299.9 kB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 299.9/299.9 kB 1.2 MB/s eta 0:00:00\n",
      "Installing collected packages: wordcloud\n",
      "Successfully installed wordcloud-1.9.4\n"
     ]
    }
   ],
   "source": [
    "!pip install wordcloud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3bd76482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Türkçe Stopwords (ilk 50):\n",
      "['ama', 'veya', 'nasıl', 'mü', 'her', 'tüm', 'için', 'o', 'ile', 'de', 'niye', 'hangi', 'ki', 'mı', 'da', 'kadar', 'bu', 'çok', 'şu', 'mu', 'ise', 'az', 'değil', 'mi', 'ya', 'ne', 'bir', 've']\n"
     ]
    }
   ],
   "source": [
    "# Türkçe stopwords listesi\n",
    "turkish_stopwords = set([\n",
    "    've', 'ile', 'de', 'da', 'ki', 'kadar', 'için', 'ama', 'ya', 'veya',\n",
    "    'bir', 'bu', 'şu', 'o', 'ne', 'nasıl', 'niye', 'hangi', 'her', 'tüm',\n",
    "    'mi', 'mı', 'mu', 'mü', 'ise', 'değil', 'çok', 'az'\n",
    "])\n",
    "print(\"Türkçe Stopwords (ilk 50):\")\n",
    "print(list(turkish_stopwords)[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "aaa4dbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basit Türkçe stemleme fonksiyonu\n",
    "def simple_turkish_stem(token):\n",
    "    # Yaygın Türkçe son ekleri kaldır\n",
    "    suffixes = ['ler', 'lar', 'in', 'ın', 'un', 'ün', 'de', 'da', 'ki', 'e', 'a']\n",
    "    for suffix in suffixes:\n",
    "        if token.endswith(suffix):\n",
    "            return token[:-len(suffix)]\n",
    "    return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e9350600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veri setini yükle\n",
    "df = pd.read_csv('C:/Users/ademt/Desktop/tarim_problemleri_veriseti.csv', encoding='utf-8')\n",
    "texts = df['sorun_metin'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dc3722aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sorun_metin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Bu yaz sezonunda şeftali tarlamızda yapraklard...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>mısır tarlamızda genç fidelerde çekiş kaybı ya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>patates tarlamızda genç fidelerde genç sürgünl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Bu yaz kurak geçtiği için sığırların genç sürg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Son hasatta traktörmizin çekiş kaybı yaşanması...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>196</td>\n",
       "      <td>Bu yaz kurak geçtiği için sığırların genç fide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>197</td>\n",
       "      <td>elma bahçemde genç fidelerde sararma ve gelişi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>198</td>\n",
       "      <td>patates bahçemde yapraklarda kahverengileşme v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>199</td>\n",
       "      <td>üzüm tarlamızda genç fidelerde yapraklarda kah...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>200</td>\n",
       "      <td>elma tarlamızda bıçakların sık sık tıkanması. ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                        sorun_metin\n",
       "0      1  Bu yaz sezonunda şeftali tarlamızda yapraklard...\n",
       "1      2  mısır tarlamızda genç fidelerde çekiş kaybı ya...\n",
       "2      3  patates tarlamızda genç fidelerde genç sürgünl...\n",
       "3      4  Bu yaz kurak geçtiği için sığırların genç sürg...\n",
       "4      5  Son hasatta traktörmizin çekiş kaybı yaşanması...\n",
       "..   ...                                                ...\n",
       "195  196  Bu yaz kurak geçtiği için sığırların genç fide...\n",
       "196  197  elma bahçemde genç fidelerde sararma ve gelişi...\n",
       "197  198  patates bahçemde yapraklarda kahverengileşme v...\n",
       "198  199  üzüm tarlamızda genç fidelerde yapraklarda kah...\n",
       "199  200  elma tarlamızda bıçakların sık sık tıkanması. ...\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a1e3bb74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verinin ilk 500 karakteri:\n",
      "Bu yaz sezonunda şeftali tarlamızda yapraklarda kahverengileşme ve büzüşme. Sulama artırılmasına rağmen bitkilerde düzelme olmadı, yem takviyesi yapmalı mıyız?\n"
     ]
    }
   ],
   "source": [
    "# İlk 500 karakteri göster\n",
    "print(\"\\nVerinin ilk 500 karakteri:\")\n",
    "print(''.join([str(text)[:500] for text in texts if isinstance(text, str)][:1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f371e8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cümlelere ayır\n",
    "sentences = []\n",
    "for text in texts:\n",
    "    if isinstance(text, str):\n",
    "        sentences.extend(sent_tokenize(text))\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dcc6c616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "İlk 10 cümle:\n",
      "['Bu yaz sezonunda şeftali tarlamızda yapraklarda kahverengileşme ve büzüşme.', 'Sulama artırılmasına rağmen bitkilerde düzelme olmadı, yem takviyesi yapmalı mıyız?', 'mısır tarlamızda genç fidelerde çekiş kaybı yaşanması.', 'aktarma organlarında sorun kaynaklı olabilir mi?', 'patates tarlamızda genç fidelerde genç sürgünlerde kurumalar ve yaprak dökümü.', 'azot eksikliği kaynaklı olabilir mi?', 'Bu yaz kurak geçtiği için sığırların genç sürgünlerde kurumalar ve yaprak dökümü.', 'gübreleme programını yeniden düzenlemeli miyim?', 'Son hasatta traktörmizin çekiş kaybı yaşanması.', 'gübreleme programını yeniden düzenlemeli miyim?']\n"
     ]
    }
   ],
   "source": [
    "# İlk 10 cümleyi göster\n",
    "print(\"\\nİlk 10 cümle:\")\n",
    "print(sentences[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "030978d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ön işleme fonksiyonu (girinti düzeltilmiş)\n",
    "def preprocess_sentence(sentence):\n",
    "    if not isinstance(sentence, str):\n",
    "        return [], []\n",
    "    \n",
    "    tokens = word_tokenize(sentence)\n",
    "    filtered_tokens = [\n",
    "        token.lower() for token in tokens\n",
    "        if token.isalpha() and token.lower() not in turkish_stopwords\n",
    "    ]\n",
    "    \n",
    "    # Lemmatizasyon (Zembereksiz: filtrelenmiş kelimeler)\n",
    "    lemmatized_tokens = filtered_tokens\n",
    "    \n",
    "    # Stemleme (basit kural tabanlı)\n",
    "    stemmed_tokens = [simple_turkish_stem(token) for token in filtered_tokens]\n",
    "    \n",
    "    return lemmatized_tokens, stemmed_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f46a65af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Örnek Cümle Çıktısı:\n",
      "Ham Cümle: Bu yaz şeftali tarlamızda yapraklarda kahverengileşme ve büzüşme.\n",
      "Lemmatized Tokens: ['yaz', 'şeftali', 'tarlamızda', 'yapraklarda', 'kahverengileşme', 'büzüşme']\n",
      "Stemmed Tokens: ['yaz', 'şeftali', 'tarlamız', 'yapraklar', 'kahverengileşm', 'büzüşm']\n"
     ]
    }
   ],
   "source": [
    "# Örnek cümleyle fonksiyon çıktısını göster\n",
    "ornek_cumle = \"Bu yaz şeftali tarlamızda yapraklarda kahverengileşme ve büzüşme.\"\n",
    "lemmatized, stemmed = preprocess_sentence(ornek_cumle)\n",
    "print(\"\\nÖrnek Cümle Çıktısı:\")\n",
    "print(f\"Ham Cümle: {ornek_cumle}\")\n",
    "print(f\"Lemmatized Tokens: {lemmatized}\")\n",
    "print(f\"Stemmed Tokens: {stemmed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c5f50a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "İlk İşlenen Cümle (Fonksiyonlu):\n",
      "Ham: Bu yaz sezonunda şeftali tarlamızda yapraklarda kahverengileşme ve büzüşme.\n",
      "Lemmatized: ['yaz', 'sezonunda', 'şeftali', 'tarlamızda', 'yapraklarda', 'kahverengileşme', 'büzüşme']\n",
      "Stemmed: ['yaz', 'sezonun', 'şeftali', 'tarlamız', 'yapraklar', 'kahverengileşm', 'büzüşm']\n"
     ]
    }
   ],
   "source": [
    "# Cümleleri işle (fonksiyonlu yaklaşım)\n",
    "tokenized_corpus_lemmatized = []\n",
    "tokenized_corpus_stemmed = []\n",
    "for sentence in sentences:\n",
    "    lemmatized_tokens, stemmed_tokens = preprocess_sentence(sentence)\n",
    "    if lemmatized_tokens:\n",
    "        tokenized_corpus_lemmatized.append(lemmatized_tokens)\n",
    "        tokenized_corpus_stemmed.append(stemmed_tokens)\n",
    "\n",
    "# İlk işlenen cümlenin çıktısını göster (fonksiyonlu)\n",
    "print(\"\\nİlk İşlenen Cümle (Fonksiyonlu):\")\n",
    "print(f\"Ham: {sentences[0]}\")\n",
    "print(f\"Lemmatized: {tokenized_corpus_lemmatized[0]}\")\n",
    "print(f\"Stemmed: {tokenized_corpus_stemmed[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "24c3984d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ayrıntılı for döngüsü ile işleme\n",
    "filtered_sentences = []\n",
    "for sentence in sentences:\n",
    "    tokens = word_tokenize(sentence)\n",
    "    filtered_tokens = []\n",
    "    for token in tokens:\n",
    "        if token.isalpha():\n",
    "            token_lower = token.lower()\n",
    "            if token_lower not in turkish_stopwords:\n",
    "                filtered_tokens.append(token_lower)\n",
    "    filtered_sentences.append(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e69d2182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatizasyon (ayrıntılı, Zembereksiz: filtrelenmiş kelimeler)\n",
    "tokenized_corpus_lemmatized_detailed = filtered_sentences\n",
    "\n",
    "# Stemleme (ayrıntılı)\n",
    "tokenized_corpus_stemmed_detailed = []\n",
    "for filtered_tokens in filtered_sentences:\n",
    "    stemmed_tokens = [simple_turkish_stem(token) for token in filtered_tokens]\n",
    "    if stemmed_tokens:\n",
    "        tokenized_corpus_stemmed_detailed.append(stemmed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3db07d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "İlk İşlenen Cümle (Ayrıntılı):\n",
      "Ham: Bu yaz sezonunda şeftali tarlamızda yapraklarda kahverengileşme ve büzüşme.\n",
      "Lemmatized: ['yaz', 'sezonunda', 'şeftali', 'tarlamızda', 'yapraklarda', 'kahverengileşme', 'büzüşme']\n",
      "Stemmed: ['yaz', 'sezonun', 'şeftali', 'tarlamız', 'yapraklar', 'kahverengileşm', 'büzüşm']\n"
     ]
    }
   ],
   "source": [
    "# İlk işlenen cümlenin çıktısını göster (ayrıntılı)\n",
    "print(\"\\nİlk İşlenen Cümle (Ayrıntılı):\")\n",
    "print(f\"Ham: {sentences[0]}\")\n",
    "print(f\"Lemmatized: {tokenized_corpus_lemmatized_detailed[0]}\")\n",
    "print(f\"Stemmed: {tokenized_corpus_stemmed_detailed[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c8f86190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatize edilmiş cümleleri CSV'ye kaydet\n",
    "with open(\"lemmatized_sentences.csv\", mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    for tokens in tokenized_corpus_lemmatized:\n",
    "        writer.writerow([' '.join(tokens)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e4b94f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemlenmiş cümleleri CSV'ye kaydet\n",
    "with open(\"stemmed_sentences.csv\", mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    for tokens in tokenized_corpus_stemmed:\n",
    "        writer.writerow([' '.join(tokens)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ef06bb62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "İlk 5 Cümle Karşılaştırması:\n",
      "Cümle 1 - Ham: Bu yaz sezonunda şeftali tarlamızda yapraklarda kahverengileşme ve büzüşme.\n",
      "Cümle 1 - Lemmatized: ['yaz', 'sezonunda', 'şeftali', 'tarlamızda', 'yapraklarda', 'kahverengileşme', 'büzüşme']\n",
      "Cümle 1 - Stemmed: ['yaz', 'sezonun', 'şeftali', 'tarlamız', 'yapraklar', 'kahverengileşm', 'büzüşm']\n",
      "\n",
      "Cümle 2 - Ham: Sulama artırılmasına rağmen bitkilerde düzelme olmadı, yem takviyesi yapmalı mıyız?\n",
      "Cümle 2 - Lemmatized: ['sulama', 'artırılmasına', 'rağmen', 'bitkilerde', 'düzelme', 'olmadı', 'yem', 'takviyesi', 'yapmalı', 'mıyız']\n",
      "Cümle 2 - Stemmed: ['sulam', 'artırılmasın', 'rağmen', 'bitkiler', 'düzelm', 'olmadı', 'yem', 'takviyesi', 'yapmalı', 'mıyız']\n",
      "\n",
      "Cümle 3 - Ham: mısır tarlamızda genç fidelerde çekiş kaybı yaşanması.\n",
      "Cümle 3 - Lemmatized: ['mısır', 'tarlamızda', 'genç', 'fidelerde', 'çekiş', 'kaybı', 'yaşanması']\n",
      "Cümle 3 - Stemmed: ['mısır', 'tarlamız', 'genç', 'fideler', 'çekiş', 'kaybı', 'yaşanması']\n",
      "\n",
      "Cümle 4 - Ham: aktarma organlarında sorun kaynaklı olabilir mi?\n",
      "Cümle 4 - Lemmatized: ['aktarma', 'organlarında', 'sorun', 'kaynaklı', 'olabilir']\n",
      "Cümle 4 - Stemmed: ['aktarm', 'organların', 'sor', 'kaynaklı', 'olabilir']\n",
      "\n",
      "Cümle 5 - Ham: patates tarlamızda genç fidelerde genç sürgünlerde kurumalar ve yaprak dökümü.\n",
      "Cümle 5 - Lemmatized: ['patates', 'tarlamızda', 'genç', 'fidelerde', 'genç', 'sürgünlerde', 'kurumalar', 'yaprak', 'dökümü']\n",
      "Cümle 5 - Stemmed: ['patates', 'tarlamız', 'genç', 'fideler', 'genç', 'sürgünler', 'kuruma', 'yaprak', 'dökümü']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# İlk 5 cümleyi yazdır\n",
    "print(\"\\nİlk 5 Cümle Karşılaştırması:\")\n",
    "for i in range(min(5, len(sentences))):\n",
    "    print(f\"Cümle {i+1} - Ham: {sentences[i]}\")\n",
    "    print(f\"Cümle {i+1} - Lemmatized: {tokenized_corpus_lemmatized[i]}\")\n",
    "    print(f\"Cümle {i+1} - Stemmed: {tokenized_corpus_stemmed[i]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "329d7dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kelime bulutu oluştur\n",
    "all_lemmatized_text = ' '.join([' '.join(tokens) for tokens in tokenized_corpus_lemmatized])\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white', font_path=None).generate(all_lemmatized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f083a732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kelime bulutunu kaydet\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.savefig('kelime_bulutu.png')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "80fc214a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ham veri boyutu (karakter): 23877\n",
      "Temizlenmiş veri boyutu (karakter): 22235\n",
      "Boyut azalması: 6.88%\n"
     ]
    }
   ],
   "source": [
    "# Veri boyutu raporlama\n",
    "raw_size = sum(len(text) for text in texts if isinstance(text, str))\n",
    "cleaned_size = len(all_lemmatized_text)\n",
    "print(f\"Ham veri boyutu (karakter): {raw_size}\")\n",
    "print(f\"Temizlenmiş veri boyutu (karakter): {cleaned_size}\")\n",
    "print(f\"Boyut azalması: {((raw_size - cleaned_size) / raw_size * 100):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb071ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
