{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1dbe4502",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import gensim\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8f33870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gerekli NLTK kaynaklarını indir (ilk çalıştırmada gerekli)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6e813c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [1] Kütüphaneleri içe aktarma \n",
    "# Yukarıda yapıldı."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84cd30e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verinin ilk 500 karakteri:\n",
      "Bu yaz sezonunda şeftali tarlamızda yapraklarda kahverengileşme ve büzüşme. Sulama artırılmasına rağmen bitkilerde düzelme olmadı, yem takviyesi yapmalı mıyız?\n"
     ]
    }
   ],
   "source": [
    "# [2] Veri setini yükleme ve ilk 500 karakteri gösterme\n",
    "df = pd.read_csv('C:/Users/ademt/Desktop/tarim_problemleri_veriseti.csv', encoding='utf-8')\n",
    "texts = df['sorun_metin'].tolist()\n",
    "print(\"Verinin ilk 500 karakteri:\")\n",
    "print(''.join([str(text)[:500] for text in texts if isinstance(text, str)][:1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46e04d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "İlk 10 cümle:\n",
      "['Bu yaz sezonunda şeftali tarlamızda yapraklarda kahverengileşme ve büzüşme.', 'Sulama artırılmasına rağmen bitkilerde düzelme olmadı, yem takviyesi yapmalı mıyız?', 'mısır tarlamızda genç fidelerde çekiş kaybı yaşanması.', 'aktarma organlarında sorun kaynaklı olabilir mi?', 'patates tarlamızda genç fidelerde genç sürgünlerde kurumalar ve yaprak dökümü.', 'azot eksikliği kaynaklı olabilir mi?', 'Bu yaz kurak geçtiği için sığırların genç sürgünlerde kurumalar ve yaprak dökümü.', 'gübreleme programını yeniden düzenlemeli miyim?', 'Son hasatta traktörmizin çekiş kaybı yaşanması.', 'gübreleme programını yeniden düzenlemeli miyim?']\n"
     ]
    }
   ],
   "source": [
    "# [3] Cümlelere ayırma ve ilk 10 cümleyi gösterme\n",
    "sentences = []\n",
    "for text in texts:\n",
    "    if isinstance(text, str):\n",
    "        sentences.extend(sent_tokenize(text))\n",
    "    else:\n",
    "        continue\n",
    "print(\"\\nİlk 10 cümle:\")\n",
    "print(sentences[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a032660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Türkçe Stopwords (ilk 50):\n",
      "['da', 'şu', 'ne', 'de', 'tüm', 'mu', 'o', 'ki', 'çok', 've', 'ama', 'hangi', 'bu', 'için', 'her', 'bir', 'az', 'ya', 'mı', 'veya', 'niye', 'ile', 'değil', 'kadar', 'ise', 'nasıl', 'mi', 'mü']\n"
     ]
    }
   ],
   "source": [
    "# [4] Türkçe stopwords listesini alma ve ilk 50’sini yazdırma\n",
    "turkish_stopwords = set([\n",
    "    've', 'ile', 'de', 'da', 'ki', 'kadar', 'için', 'ama', 'ya', 'veya',\n",
    "    'bir', 'bu', 'şu', 'o', 'ne', 'nasıl', 'niye', 'hangi', 'her', 'tüm',\n",
    "    'mi', 'mı', 'mu', 'mü', 'ise', 'değil', 'çok', 'az'\n",
    "])\n",
    "stop_words_list = list(turkish_stopwords)\n",
    "print(\"\\nTürkçe Stopwords (ilk 50):\")\n",
    "print(stop_words_list[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91b83c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [5] Stemleme fonksiyonunu başlatma\n",
    "def simple_turkish_stem(token):\n",
    "    suffixes = ['ler', 'lar', 'in', 'ın', 'un', 'ün', 'de', 'da', 'ki', 'e', 'a']\n",
    "    for suffix in suffixes:\n",
    "        if token.endswith(suffix):\n",
    "            return token[:-len(suffix)]\n",
    "    return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d35ce08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [6] Ön işleme fonksiyonunu tanımlama\n",
    "def preprocess_sentence(sentence):\n",
    "    if not isinstance(sentence, str):\n",
    "        return [], []\n",
    "    tokens = word_tokenize(sentence)\n",
    "    filtered_tokens = [token.lower() for token in tokens if token.isalpha() and token.lower() not in turkish_stopwords]\n",
    "    lemmatized_tokens = filtered_tokens  # Zembereksiz: filtrelenmiş kelimeler\n",
    "    stemmed_tokens = [simple_turkish_stem(token) for token in filtered_tokens]\n",
    "    return lemmatized_tokens, stemmed_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6f7ddfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [7-8] Cümleleri işleme (fonksiyonlu)\n",
    "tokenized_corpus_lemmatized = []\n",
    "tokenized_corpus_stemmed = []\n",
    "for sentence in sentences:\n",
    "    lemmatized_tokens, stemmed_tokens = preprocess_sentence(sentence)\n",
    "    tokenized_corpus_lemmatized.append(lemmatized_tokens)\n",
    "    tokenized_corpus_stemmed.append(stemmed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70b7c3fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "İlk İşlenen Cümle (Fonksiyonlu):\n",
      "Ham: Bu yaz sezonunda şeftali tarlamızda yapraklarda kahverengileşme ve büzüşme.\n",
      "Lemmatized: ['yaz', 'sezonunda', 'şeftali', 'tarlamızda', 'yapraklarda', 'kahverengileşme', 'büzüşme']\n",
      "Stemmed: ['yaz', 'sezonun', 'şeftali', 'tarlamız', 'yapraklar', 'kahverengileşm', 'büzüşm']\n"
     ]
    }
   ],
   "source": [
    "# İlk işlenen cümlenin çıktısını göster\n",
    "print(\"\\nİlk İşlenen Cümle (Fonksiyonlu):\")\n",
    "print(f\"Ham: {sentences[0]}\")\n",
    "print(f\"Lemmatized: {tokenized_corpus_lemmatized[0]}\")\n",
    "print(f\"Stemmed: {tokenized_corpus_stemmed[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1fb6510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [9] Lemmatize edilmiş cümleleri CSV’ye kaydetme\n",
    "with open(\"lemmatized_sentences.csv\", mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    for tokens in tokenized_corpus_lemmatized:\n",
    "        writer.writerow([' '.join(tokens)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62860536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [10] Stemlenmiş cümleleri CSV’ye kaydetme\n",
    "with open(\"stemmed_sentences.csv\", mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    for tokens in tokenized_corpus_stemmed:\n",
    "        writer.writerow([' '.join(tokens)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a5f9dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "İlk 5 Cümle Karşılaştırması (Fonksiyonlu):\n",
      "Cümle 1 - Ham: Bu yaz sezonunda şeftali tarlamızda yapraklarda kahverengileşme ve büzüşme.\n",
      "Cümle 1 - Lemmatized: ['yaz', 'sezonunda', 'şeftali', 'tarlamızda', 'yapraklarda', 'kahverengileşme', 'büzüşme']\n",
      "Cümle 1 - Stemmed: ['yaz', 'sezonun', 'şeftali', 'tarlamız', 'yapraklar', 'kahverengileşm', 'büzüşm']\n",
      "\n",
      "Cümle 2 - Ham: Sulama artırılmasına rağmen bitkilerde düzelme olmadı, yem takviyesi yapmalı mıyız?\n",
      "Cümle 2 - Lemmatized: ['sulama', 'artırılmasına', 'rağmen', 'bitkilerde', 'düzelme', 'olmadı', 'yem', 'takviyesi', 'yapmalı', 'mıyız']\n",
      "Cümle 2 - Stemmed: ['sulam', 'artırılmasın', 'rağmen', 'bitkiler', 'düzelm', 'olmadı', 'yem', 'takviyesi', 'yapmalı', 'mıyız']\n",
      "\n",
      "Cümle 3 - Ham: mısır tarlamızda genç fidelerde çekiş kaybı yaşanması.\n",
      "Cümle 3 - Lemmatized: ['mısır', 'tarlamızda', 'genç', 'fidelerde', 'çekiş', 'kaybı', 'yaşanması']\n",
      "Cümle 3 - Stemmed: ['mısır', 'tarlamız', 'genç', 'fideler', 'çekiş', 'kaybı', 'yaşanması']\n",
      "\n",
      "Cümle 4 - Ham: aktarma organlarında sorun kaynaklı olabilir mi?\n",
      "Cümle 4 - Lemmatized: ['aktarma', 'organlarında', 'sorun', 'kaynaklı', 'olabilir']\n",
      "Cümle 4 - Stemmed: ['aktarm', 'organların', 'sor', 'kaynaklı', 'olabilir']\n",
      "\n",
      "Cümle 5 - Ham: patates tarlamızda genç fidelerde genç sürgünlerde kurumalar ve yaprak dökümü.\n",
      "Cümle 5 - Lemmatized: ['patates', 'tarlamızda', 'genç', 'fidelerde', 'genç', 'sürgünlerde', 'kurumalar', 'yaprak', 'dökümü']\n",
      "Cümle 5 - Stemmed: ['patates', 'tarlamız', 'genç', 'fideler', 'genç', 'sürgünler', 'kuruma', 'yaprak', 'dökümü']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# [11] İlk 5 cümlenin ham, lemmatize ve stemlenmiş hallerini yazdırma\n",
    "print(\"\\nİlk 5 Cümle Karşılaştırması (Fonksiyonlu):\")\n",
    "for i in range(min(5, len(sentences))):\n",
    "    print(f\"Cümle {i+1} - Ham: {sentences[i]}\")\n",
    "    print(f\"Cümle {i+1} - Lemmatized: {tokenized_corpus_lemmatized[i]}\")\n",
    "    print(f\"Cümle {i+1} - Stemmed: {tokenized_corpus_stemmed[i]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d163b80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [12-15] Kütüphaneler, veri yükleme, cümlelere ayırma, stopwords \n",
    "# Zaten [1-4]’te yapıldı."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f45a181d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [16-17] Ayrıntılı for döngüsü ile kelimeleri tokenleştirme ve filtreleme\n",
    "filtered_sentences = []\n",
    "for sentence in sentences:\n",
    "    tokens = word_tokenize(sentence)\n",
    "    filtered_tokens = []\n",
    "    for token in tokens:\n",
    "        if token.isalpha():\n",
    "            token_lower = token.lower()\n",
    "            if token_lower not in turkish_stopwords:\n",
    "                filtered_tokens.append(token_lower)\n",
    "    filtered_sentences.append(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4efd0461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [18] Lemmatize edilmiş cümleleri oluşturma (ayrıntılı, Zembereksiz)\n",
    "tokenized_corpus_lemmatized_detailed = filtered_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9524adf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ayrıntılı Stemlenmiş Cümleler (ilk 10):\n",
      "[['yaz', 'sezonun', 'şeftali', 'tarlamız', 'yapraklar', 'kahverengileşm', 'büzüşm'], ['sulam', 'artırılmasın', 'rağmen', 'bitkiler', 'düzelm', 'olmadı', 'yem', 'takviyesi', 'yapmalı', 'mıyız'], ['mısır', 'tarlamız', 'genç', 'fideler', 'çekiş', 'kaybı', 'yaşanması'], ['aktarm', 'organların', 'sor', 'kaynaklı', 'olabilir'], ['patates', 'tarlamız', 'genç', 'fideler', 'genç', 'sürgünler', 'kuruma', 'yaprak', 'dökümü'], ['azot', 'eksikliği', 'kaynaklı', 'olabilir'], ['yaz', 'kurak', 'geçtiği', 'sığırlar', 'genç', 'sürgünler', 'kuruma', 'yaprak', 'dökümü'], ['gübrelem', 'programını', 'yeniden', 'düzenlemeli', 'miyim'], ['son', 'hasatt', 'traktörmiz', 'çekiş', 'kaybı', 'yaşanması'], ['gübrelem', 'programını', 'yeniden', 'düzenlemeli', 'miyim']]\n"
     ]
    }
   ],
   "source": [
    "# [19] Ayrıntılı stemleme\n",
    "tokenized_corpus_stemmed_detailed = []\n",
    "for filtered_tokens in filtered_sentences:\n",
    "    stemmed_tokens = [simple_turkish_stem(token) for token in filtered_tokens]\n",
    "    tokenized_corpus_stemmed_detailed.append(stemmed_tokens)\n",
    "print(\"\\nAyrıntılı Stemlenmiş Cümleler (ilk 10):\")\n",
    "print(tokenized_corpus_stemmed_detailed[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "acafb34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [20] Ayrıntılı stemlenmiş cümleleri CSV’ye kaydetme\n",
    "with open(\"stemmed_sentences_detailed.csv\", mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    for tokens in tokenized_corpus_stemmed_detailed:\n",
    "        writer.writerow([' '.join(tokens)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6033821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "İlk 5 Cümle Karşılaştırması (Ayrıntılı):\n",
      "Cümle 1 - Ham: Bu yaz sezonunda şeftali tarlamızda yapraklarda kahverengileşme ve büzüşme.\n",
      "Cümle 1 - Lemmatized: ['yaz', 'sezonunda', 'şeftali', 'tarlamızda', 'yapraklarda', 'kahverengileşme', 'büzüşme']\n",
      "Cümle 1 - Stemmed: ['yaz', 'sezonun', 'şeftali', 'tarlamız', 'yapraklar', 'kahverengileşm', 'büzüşm']\n",
      "\n",
      "Cümle 2 - Ham: Sulama artırılmasına rağmen bitkilerde düzelme olmadı, yem takviyesi yapmalı mıyız?\n",
      "Cümle 2 - Lemmatized: ['sulama', 'artırılmasına', 'rağmen', 'bitkilerde', 'düzelme', 'olmadı', 'yem', 'takviyesi', 'yapmalı', 'mıyız']\n",
      "Cümle 2 - Stemmed: ['sulam', 'artırılmasın', 'rağmen', 'bitkiler', 'düzelm', 'olmadı', 'yem', 'takviyesi', 'yapmalı', 'mıyız']\n",
      "\n",
      "Cümle 3 - Ham: mısır tarlamızda genç fidelerde çekiş kaybı yaşanması.\n",
      "Cümle 3 - Lemmatized: ['mısır', 'tarlamızda', 'genç', 'fidelerde', 'çekiş', 'kaybı', 'yaşanması']\n",
      "Cümle 3 - Stemmed: ['mısır', 'tarlamız', 'genç', 'fideler', 'çekiş', 'kaybı', 'yaşanması']\n",
      "\n",
      "Cümle 4 - Ham: aktarma organlarında sorun kaynaklı olabilir mi?\n",
      "Cümle 4 - Lemmatized: ['aktarma', 'organlarında', 'sorun', 'kaynaklı', 'olabilir']\n",
      "Cümle 4 - Stemmed: ['aktarm', 'organların', 'sor', 'kaynaklı', 'olabilir']\n",
      "\n",
      "Cümle 5 - Ham: patates tarlamızda genç fidelerde genç sürgünlerde kurumalar ve yaprak dökümü.\n",
      "Cümle 5 - Lemmatized: ['patates', 'tarlamızda', 'genç', 'fidelerde', 'genç', 'sürgünlerde', 'kurumalar', 'yaprak', 'dökümü']\n",
      "Cümle 5 - Stemmed: ['patates', 'tarlamız', 'genç', 'fideler', 'genç', 'sürgünler', 'kuruma', 'yaprak', 'dökümü']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# [21] İlk 5 cümlenin ayrıntılı işlenmiş hallerini yazdırma\n",
    "print(\"\\nİlk 5 Cümle Karşılaştırması (Ayrıntılı):\")\n",
    "for i in range(min(5, len(sentences))):\n",
    "    print(f\"Cümle {i+1} - Ham: {sentences[i]}\")\n",
    "    print(f\"Cümle {i+1} - Lemmatized: {tokenized_corpus_lemmatized_detailed[i]}\")\n",
    "    print(f\"Cümle {i+1} - Stemmed: {tokenized_corpus_stemmed_detailed[i]}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cac68c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "İlk 3 lemmatized metin:\n",
      "['yaz sezonunda şeftali tarlamızda yapraklarda kahverengileşme büzüşme', 'sulama artırılmasına rağmen bitkilerde düzelme olmadı yem takviyesi yapmalı mıyız', 'mısır tarlamızda genç fidelerde çekiş kaybı yaşanması']\n"
     ]
    }
   ],
   "source": [
    "# 2. Hafta: TF-IDF Vektörizasyon \n",
    "# [1] Ön işleme (zaten yapıldı, lemmatize verileri kullanacağım)\n",
    "\n",
    "# [2-3] Lemmatize metinleri oluşturma ve ilk 3’ünü gösterme\n",
    "lemmatized_texts = [' '.join(tokens) for tokens in tokenized_corpus_lemmatized]\n",
    "print(\"\\nİlk 3 lemmatized metin:\")\n",
    "print(lemmatized_texts[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "48e21a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [4] TF-IDF vektörizasyon\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(lemmatized_texts)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53752944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "İlk 5 cümlenin TF-IDF skorları:\n",
      "   acil   aktarma  aldığımız  analizi  arttı  artırılmasına  atların  \\\n",
      "0   0.0  0.000000        0.0      0.0    0.0       0.000000      0.0   \n",
      "1   0.0  0.000000        0.0      0.0    0.0       0.312483      0.0   \n",
      "2   0.0  0.000000        0.0      0.0    0.0       0.000000      0.0   \n",
      "3   0.0  0.487473        0.0      0.0    0.0       0.000000      0.0   \n",
      "4   0.0  0.000000        0.0      0.0    0.0       0.000000      0.0   \n",
      "\n",
      "   azalması  azot  açmalı  ...  yumuşama  zeytin  zeytinlerde     çekiş  \\\n",
      "0       0.0   0.0     0.0  ...       0.0     0.0          0.0  0.000000   \n",
      "1       0.0   0.0     0.0  ...       0.0     0.0          0.0  0.000000   \n",
      "2       0.0   0.0     0.0  ...       0.0     0.0          0.0  0.398635   \n",
      "3       0.0   0.0     0.0  ...       0.0     0.0          0.0  0.000000   \n",
      "4       0.0   0.0     0.0  ...       0.0     0.0          0.0  0.000000   \n",
      "\n",
      "   çürüklüğü  çürümesi  üzüm  üzümlerde   şeftali  şeftalilerde  \n",
      "0        0.0       0.0   0.0        0.0  0.468997           0.0  \n",
      "1        0.0       0.0   0.0        0.0  0.000000           0.0  \n",
      "2        0.0       0.0   0.0        0.0  0.000000           0.0  \n",
      "3        0.0       0.0   0.0        0.0  0.000000           0.0  \n",
      "4        0.0       0.0   0.0        0.0  0.000000           0.0  \n",
      "\n",
      "[5 rows x 143 columns]\n"
     ]
    }
   ],
   "source": [
    "# [5] İlk 5 cümlenin TF-IDF skorlarını yazdırma\n",
    "print(\"\\nİlk 5 cümlenin TF-IDF skorları:\")\n",
    "print(tfidf_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ce66f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "İlk cümlede en yüksek TF-IDF skoruna sahip 5 kelime:\n",
      "şeftali            0.468997\n",
      "büzüşme            0.387385\n",
      "kahverengileşme    0.387385\n",
      "yapraklarda        0.387385\n",
      "sezonunda          0.387385\n",
      "Name: 0, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# İlk cümle için TF-IDF skorlarını al\n",
    "first_sentence_vector = tfidf_df.iloc[0]\n",
    "top_5_words = first_sentence_vector.sort_values(ascending=False).head(5)\n",
    "print(\"\\nİlk cümlede en yüksek TF-IDF skoruna sahip 5 kelime:\")\n",
    "print(top_5_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "82a07b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'sorun' kelimesine en benzer 5 kelime:\n",
      "durum: 0.1135\n",
      "belirtisi: 0.1135\n",
      "olabilir: 0.1747\n",
      "organlarında: 1.0000\n",
      "sorun: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# [6] \"sorun\" kelimesi için cosine benzerlik analizi\n",
    "try:\n",
    "    sorun_index = list(feature_names).index('sorun')\n",
    "    sorun_vector = tfidf_matrix[:, sorun_index].toarray()\n",
    "    tfidf_vectors = tfidf_matrix.toarray()\n",
    "    similarities = cosine_similarity(sorun_vector.T, tfidf_vectors.T)\n",
    "    similarities = similarities.flatten()\n",
    "    top_5_indices = similarities.argsort()[-6:][:-1]\n",
    "    print(\"\\n'sorun' kelimesine en benzer 5 kelime:\")\n",
    "    for index in top_5_indices:\n",
    "        print(f\"{feature_names[index]}: {similarities[index]:.4f}\")\n",
    "except ValueError:\n",
    "    print(\"\\n'sorun' kelimesi veri setinde bulunamadı.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d8824419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Hafta: Word2Vec Model Eğitimi \n",
    "# [16] Word2Vec modelleri eğitme\n",
    "# Ön işleme zaten yapıldı, tokenized_corpus_lemmatized ve tokenized_corpus_stemmed kullanacağım\n",
    "\n",
    "# Word2Vec modeli eğitmek için parametreler\n",
    "parameters = [\n",
    "    {'model_type': 'cbow', 'window': 2, 'vector_size': 100},\n",
    "    {'model_type': 'skipgram', 'window': 2, 'vector_size': 100},\n",
    "    {'model_type': 'cbow', 'window': 4, 'vector_size': 100},\n",
    "    {'model_type': 'skipgram', 'window': 4, 'vector_size': 100},\n",
    "    {'model_type': 'cbow', 'window': 2, 'vector_size': 300},\n",
    "    {'model_type': 'cbow', 'window': 4, 'vector_size': 300},\n",
    "    {'model_type': 'skipgram', 'window': 4, 'vector_size': 300}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "df86612d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonksiyon ile Word2Vec modeli eğitme ve kaydetme\n",
    "def train_and_save_model(corpus, params, model_name):\n",
    "    model = Word2Vec(corpus, vector_size=params['vector_size'],\n",
    "                     window=params['window'], min_count=1,\n",
    "                     sg=1 if params['model_type'] == 'skipgram' else 0)\n",
    "    model.save(f\"{model_name}_{params['model_type']}_window{params['window']}_dim{params['vector_size']}.model\")\n",
    "    print(f\"{model_name}_{params['model_type']}_window{params['window']}_dim{params['vector_size']}.model saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "49340fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8c1cfc37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemmatized_model_cbow_window2_dim100.model saved!\n",
      "lemmatized_model_skipgram_window2_dim100.model saved!\n",
      "lemmatized_model_cbow_window4_dim100.model saved!\n",
      "lemmatized_model_skipgram_window4_dim100.model saved!\n",
      "lemmatized_model_cbow_window2_dim300.model saved!\n",
      "lemmatized_model_cbow_window4_dim300.model saved!\n",
      "lemmatized_model_skipgram_window4_dim300.model saved!\n",
      "stemmed_model_cbow_window2_dim100.model saved!\n",
      "stemmed_model_skipgram_window2_dim100.model saved!\n",
      "stemmed_model_cbow_window4_dim100.model saved!\n",
      "stemmed_model_skipgram_window4_dim100.model saved!\n",
      "stemmed_model_cbow_window2_dim300.model saved!\n",
      "stemmed_model_cbow_window4_dim300.model saved!\n",
      "stemmed_model_skipgram_window4_dim300.model saved!\n"
     ]
    }
   ],
   "source": [
    "# Lemmatize edilmiş corpus ile modelleri eğitme ve kaydetme\n",
    "for param in parameters:\n",
    "    train_and_save_model(tokenized_corpus_lemmatized, param, \"lemmatized_model\")\n",
    "    # Stemlenmiş corpus ile modelleri eğitme ve kaydetme\n",
    "for param in parameters:\n",
    "    train_and_save_model(tokenized_corpus_stemmed, param, \"stemmed_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b2f0447e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lemmatized CBOW Window 2 Dim 100 Modeli - 'sorun' ile En Benzer 3 Kelime:\n",
      "Kelime: düzenlemeli, Benzerlik Skoru: 0.3071\n",
      "Kelime: gelişim, Benzerlik Skoru: 0.2873\n",
      "Kelime: makinesimizin, Benzerlik Skoru: 0.2793\n",
      "\n",
      "Stemmed Skipgram Window 2 Dim 300 Modeli - 'sorun' ile En Benzer 3 Kelime:\n",
      "Kelime: tar, Benzerlik Skoru: 0.0686\n",
      "Kelime: ver, Benzerlik Skoru: 0.0404\n",
      "Kelime: gübr, Benzerlik Skoru: 0.0158\n",
      "\n",
      "Lemmatized Skipgram Window 2 Dim 300 Modeli - 'sorun' ile En Benzer 3 Kelime:\n",
      "Kelime: tarım, Benzerlik Skoru: 0.0686\n",
      "Kelime: verim, Benzerlik Skoru: 0.0404\n",
      "Kelime: gübre, Benzerlik Skoru: 0.0158\n"
     ]
    }
   ],
   "source": [
    "# [17] Üç model yükleme ve \"sorun\" kelimesi için en benzer 3 kelimeyi yazdırma\n",
    "# Model dosyalarını yükleme\n",
    "try:\n",
    "    model_1 = Word2Vec.load(\"lemmatized_model_cbow_window2_dim100.model\")\n",
    "    model_2 = Word2Vec.load(\"stemmed_model_skipgram_window2_dim300.model\")\n",
    "    model_3 = Word2Vec.load(\"lemmatized_model_skipgram_window2_dim300.model\")\n",
    "\n",
    "    # 'sorun' kelimesi ile en benzer 3 kelimeyi ve skorlarını yazdırma\n",
    "    def print_similar_words(model, model_name):\n",
    "        try:\n",
    "            similarity = model.wv.most_similar('sorun', topn=3)\n",
    "            print(f\"\\n{model_name} Modeli - 'sorun' ile En Benzer 3 Kelime:\")\n",
    "            for word, score in similarity:\n",
    "                print(f\"Kelime: {word}, Benzerlik Skoru: {score:.4f}\")\n",
    "        except KeyError:\n",
    "            print(f\"\\n{model_name} Modeli - 'sorun' kelimesi modelde bulunamadı.\")\n",
    "\n",
    "    # 3 model için benzer kelimeleri yazdırma\n",
    "    print_similar_words(model_1, \"Lemmatized CBOW Window 2 Dim 100\")\n",
    "    print_similar_words(model_2, \"Stemmed Skipgram Window 2 Dim 300\")\n",
    "    print_similar_words(model_3, \"Lemmatized Skipgram Window 2 Dim 300\")\n",
    "except FileNotFoundError:\n",
    "    print(\"\\nModellerden biri bulunamadı. Önce modelleri eğitip kaydedin.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057f80d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
